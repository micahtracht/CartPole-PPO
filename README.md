## Cartpole with PPO

In this project, I implemented proximal policy optimization from the paper onto cartpole.

It was a lot of fun to code, and a great learning experience in reading papers and implementing algorithms. No intent to make this repo any more polished, this was just a quick learning exercise for me.

Massive thanks to the OpenAI team for the PPO paper (was a surprisingly fun read) and for the PPO docs on their website that made implementation so much easier.